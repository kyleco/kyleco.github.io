---
title: Syllabus
author: Kyle Carlson
layout: default
---

Instructor: Kyle Carlson

Experiments are commonly used in software and internet businesses to evaluate product changes, marketing strategies, and other decisions. Expertise in applying experiments in this context is valuable skill that this course will help students develop. We will cover fundamentals of causality, experimental design, and statistical analysis. In addition we will devote special attention to the particular challenges of experiments in a software business environment. We will analyze how these challenges relate to the theory of causality and assumptions of statistical approaches. Students will learn to build intuition about these problems using simulation.

## Course Goals
Students should learn the following by completing the course:
- How to think critically about causality and experiments. This skill includes a critical and skeptical attitude towards claims and analysis regarding causality. Students should understand the fundamental problem of causal inference and to what extent experiments can solve the problem when implemented correctly. Students should be able to understand current debates about the reliability of experiments and statistics.
- How to use experiments to understand causal relationships and make decisions. This skill includes knowledge of experiment design and statistical analysis. However, because this is an applied course, students should learn how to adapt the design and analysis towards the practical goals of their organization.
- How to identify and address practical complications in experiments. Experiments in software or internet businesses present numerous challenges that are less often seen in a research setting. Students should learn how to minimize practical threats to the validity of their experiments.
- How to plan and evaluate experiments using simulations. Experimenters can use simulations to quickly understand complications and potential solutions. This skill is especially useful in the applied setting when theoretical approaches may be too time consuming or difficult to communicate.

## Schedule

| Date | Topics
| 8/19 | 
| ~~8/26~~ (Canceled) |
| 8/30 |
| ~~9/2~~ (Canceled: Labor Day)  |
| 9/9  |
| 9/16 |
| 9/23 |
| 9/30 |
| 10/7 |

## Related courses

- ["The Statistics of Causal Inference in the Social Sciences" (Sekhon, UC Berkeley)](http://sekhon.berkeley.edu/causalinf/)
- ["Measuring Impact in Practice" (Broockman, Stanford GSB)](https://explorecourses.stanford.edu/search?view=catalog&filter-coursestatus-Active=on&q=MGTECON%20383:%20Measuring%20Impact%20in%20Practice&academicYear=20162017) [[materials]](https://www.dropbox.com/s/dyyto6qmme4edu4/Shared%20Publicly%20-%20Broockman%20Measuring%20Impact%20Class-20180605T040309Z-001.zip?dl=0)
- ["From Data to Decisions: The Role of Experiments" (Luca, Harvard Business School)](https://webcache.googleusercontent.com/search?q=cache:hta0-Wdar8gJ:https://www.hbs.edu/coursecatalog/2205.html+&cd=2&hl=en&ct=clnk&gl=us)